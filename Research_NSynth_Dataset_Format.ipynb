{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Research_NSynth_Dataset_Format.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "nuLYDAtn1mdL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## NSynth Datasetのデータフォーマット確認\n",
        "\n",
        "https://magenta.tensorflow.org/datasets/nsynth#format\n",
        "\n",
        "まずはセットアップ"
      ]
    },
    {
      "metadata": {
        "id": "LwETTwkN1o7r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Set Sound Length (in Seconds) { vertical-output: true, run: \"auto\" }\n",
        "sample_time = 4.0 #@param {type:\"number\"}\n",
        "sr = 16000\n",
        "length = int(sr * sample_time)\n",
        "# gansynthのデータは (length/sr) = 4sec が使われている。実装確認済み\n",
        "# https://github.com/tensorflow/magenta/blob/master/magenta/models/gansynth/lib/datasets.py#L83"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r_tqdEQbsnDV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# NSynthの小さめのテストデータをダウンロード\n",
        "!wget http://download.magenta.tensorflow.org/datasets/nsynth/nsynth-test.tfrecord"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JnDex4d1s5Ip",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "filename = 'nsynth-test.tfrecord'\n",
        "filename_queue = tf.train.string_input_producer([filename])\n",
        "reader = tf.TFRecordReader()\n",
        "_, serialized_example = reader.read(filename_queue)\n",
        "\n",
        "example = tf.parse_single_example(\n",
        "    serialized_example,\n",
        "      features = {\n",
        "          'pitch': tf.FixedLenFeature([1], dtype=tf.int64),\n",
        "          'audio': tf.FixedLenFeature([length], dtype=tf.float32),\n",
        "          'qualities': tf.FixedLenFeature([10], dtype=tf.int64),\n",
        "          'instrument_source': tf.FixedLenFeature([1], dtype=tf.int64),\n",
        "          'instrument_family': tf.FixedLenFeature([1], dtype=tf.int64),\n",
        "      })\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KMLoKSGDtinb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# データの取り出しと保存\n",
        "out_filename = 'out_file.tfrecord'\n",
        "with tf.python_io.TFRecordWriter( out_filename ) as writer:\n",
        "  for record in tf.python_io.tf_record_iterator(filename):\n",
        "    example = tf.train.Example()\n",
        "    example.ParseFromString(record)\n",
        "    # gansynth では次の5つの値を使っている。audio以外は訓練データに使わないように除外するフィルタとして利用している\n",
        "    # https://github.com/tensorflow/magenta/blob/master/magenta/models/gansynth/lib/datasets.py#L114\n",
        "    p = example.features.feature[\"pitch\"].int64_list.value[0] # この音階のみ4secに入っている。細かい説明はNSynth Datasetの冒頭にあり\n",
        "    a = example.features.feature[\"audio\"].float_list.value # 実データ 64000 length\n",
        "    q = example.features.feature[\"qualities\"].int64_list.value\n",
        "    inst_src = example.features.feature[\"instrument_source\"].int64_list.value[0]\n",
        "    inst_fam = example.features.feature[\"instrument_family\"].int64_list.value[0]\n",
        "\n",
        "    if inst_src == 0: # accoustic only \n",
        "      w_example = tf.train.Example(features=tf.train.Features(feature={\n",
        "                          \"pitch\": tf.train.Feature(int64_list=tf.train.Int64List(value=[p])),\n",
        "                          \"audio\": tf.train.Feature(float_list=tf.train.FloatList(value=a)),\n",
        "                          \"qualities\": tf.train.Feature(int64_list=tf.train.Int64List(value=q)),\n",
        "                          \"instrument_source\": tf.train.Feature(int64_list=tf.train.Int64List(value=[inst_src])),\n",
        "                          \"instrument_family\": tf.train.Feature(int64_list=tf.train.Int64List(value=[inst_fam]))\n",
        "                          }))\n",
        "\n",
        "      writer.write(w_example.SerializeToString())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pRYz-GSrnspV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 保存したデータの確認\n",
        "\n",
        "参考サイト: 2018/5/19にPyCon mini Osakaで「librosaで始める音楽情報検索」\n",
        "http://www.hiromasa.info/posts/5/"
      ]
    },
    {
      "metadata": {
        "id": "TDyGp9-nacpI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# データの取り出し\n",
        "\n",
        "import IPython.display\n",
        "\n",
        "NUM_THREADS = 8\n",
        "BATCH_SIZE = 100\n",
        "\n",
        "def _parse_function(serialized):\n",
        "    features={\n",
        "          'pitch': tf.FixedLenFeature([1], dtype=tf.int64),\n",
        "          'audio': tf.FixedLenFeature([length], dtype=tf.float32),\n",
        "          'qualities': tf.FixedLenFeature([10], dtype=tf.int64),\n",
        "          'instrument_source': tf.FixedLenFeature([1], dtype=tf.int64),\n",
        "          'instrument_family': tf.FixedLenFeature([1], dtype=tf.int64),\n",
        "        }\n",
        "    p = tf.parse_single_example(serialized, features)  # データ構造を解析\n",
        "    \n",
        "    return (p[\"pitch\"], \n",
        "            p[\"audio\"], \n",
        "            p[\"qualities\"], \n",
        "            p[\"instrument_source\"], \n",
        "            p[\"instrument_family\"])\n",
        "  \n",
        "with tf.Session() as sess:\n",
        "  dataset = tf.data.TFRecordDataset(out_filename).shuffle(True).map(_parse_function, NUM_THREADS).batch(BATCH_SIZE)\n",
        "\n",
        "  iter = dataset.make_one_shot_iterator()  # イテレータを初期化\n",
        "  item = iter.get_next()  # イテレータの次の要素を取得\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "\n",
        "  while(True):\n",
        "    (p,a,q,inst_src,inst_fam) = sess.run(item)\n",
        "    #example = tf.train.Example()\n",
        "    #example.ParseFromString(record)\n",
        "    print('{}'.format(a[0]))\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nrz2ks63mrhS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "IPython.display.Audio(data=a[10], rate=sr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3R8FGQ1KbvgP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import librosa.display\n",
        "import numpy as np\n",
        "\n",
        "# 波形の描画\n",
        "librosa.display.waveplot(np.asarray(a[10]), sr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "roLOhc39nFhx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 短時間フーリエ変換\n",
        "D = librosa.stft(a[10])\n",
        "\n",
        "# スペクトグラム\n",
        "fig = plt.figure(1, figsize=(12,4)); ax = fig.add_subplot(1,1,1)\n",
        "\n",
        "log_power = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
        "librosa.display.specshow(log_power, x_axis=\"time\", y_axis=\"linear\")\n",
        "plt.colorbar()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jQYbf3xWokfJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 新たにデータセットを作れるのか？\n",
        "\n",
        "作ってみようかと思ったが、1レコードを1音階に制限して作ることがわかり、市販の音源を1音階のみ取り出すのは容易ではないことが想定され、オリジナルまたは別のデータセットをどのように揃えるか課題がある。"
      ]
    },
    {
      "metadata": {
        "id": "-3W3WW2a0uQs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "\n",
        "sr = 16000\n",
        "sample_length = 64000\n",
        "audio, _ = librosa.load('generated_clip.wav', sr=sr)\n",
        "audio = audio[:sample_length]\n",
        "len(audio)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}